{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import kstest, mannwhitneyu\n",
    "from scipy.stats import ks_2samp\n",
    "import itertools\n",
    "# import shap\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pingouin as pg\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "met_file_path = \"C:/Users/shrra/Downloads/merged_n586_Alasdair_May21_concatenated_renamed.csv\"\n",
    "met1_df = pd.read_csv(met_file_path)\n",
    "# print(met1_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met1_df_T  = met1_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "met1_df_T.reset_index(inplace=True)\n",
    "\n",
    "# Set the first row as the header\n",
    "met1_df_T.columns = met1_df_T.iloc[0]\n",
    "met1_df_T = met1_df_T[1:]\n",
    "\n",
    "# Reset the index again (if you want to have a clean numeric index)\n",
    "met1_df_T.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Rename the newly created index column (if needed)\n",
    "met1_df_T.rename(columns={met1_df_T.columns[0]: 'ID'}, inplace=True)\n",
    "\n",
    "\n",
    "# print(met1_df_T.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met1_df_T['ID'] = met1_df_T['ID'].str.replace('-S.*', '', regex=True)\n",
    "# print(len(met1_df_T))\n",
    "# print(met1_df_T.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mas_file_path = \"C:/Users/shrra/Downloads/MASH_biomarkers_clinicaldata_notimputed_May30_HH.csv\"\n",
    "mash_df = pd.read_csv(mas_file_path)\n",
    "mash_df['MASH'] = mash_df['MASH'].map({'MASH': 1, 'non-MASH': 0})\n",
    "# print(mash_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_df = mash_df[['ID', 'MASH']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_df['ID'] = id_df['ID'].str.replace('5-00', '')\n",
    "id_df['ID'] = id_df['ID'].str.replace('5-0', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = id_df[['ID']]\n",
    "df2 = met1_df_T[['ID']]\n",
    "\n",
    "\n",
    "set1 = set(df1['ID'])\n",
    "set2 = set(df2['ID'])\n",
    "\n",
    "# Find values in df1['ID'] that are not in df2['ID']\n",
    "missing_in_df2 = set1 - set2\n",
    "\n",
    "# Find values in df2['ID'] that are not in df1['ID']\n",
    "missing_in_df1 = set2 - set1\n",
    "\n",
    "# # Display the missing values\n",
    "# print(\"\\nID Values in mash file that are not in metab file\")\n",
    "# print(missing_in_df2)\n",
    "# print(len(missing_in_df2))\n",
    "# print(\"\\nID Values in metab file that are not in mash file\")\n",
    "# print(missing_in_df1)\n",
    "# print(len(missing_in_df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Updated_meta_df = pd.merge(id_df, met1_df_T, on=['ID'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KSTest_df = Updated_meta_df\n",
    "\n",
    "\n",
    "excluded_cols = [\"ID\"]\n",
    "KSTest_df= KSTest_df.drop(columns=excluded_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Assuming KSTest_df is your DataFrame\n",
    "target_column = 'MASH'\n",
    "\n",
    "# Calculate p-values for each feature in advance and store in a dictionary\n",
    "p_values_dict = {}\n",
    "for feature in KSTest_df.columns:\n",
    "    if feature != target_column:\n",
    "        Controls = KSTest_df[KSTest_df[target_column] == 0][feature].dropna()\n",
    "        MASH = KSTest_df[KSTest_df[target_column] == 1][feature].dropna()\n",
    "\n",
    "        # Ensure the columns are numeric\n",
    "        Controls = pd.to_numeric(Controls, errors='coerce')\n",
    "        MASH = pd.to_numeric(MASH, errors='coerce')\n",
    "\n",
    "        _, KS_p_value = ks_2samp(Controls, MASH)\n",
    "        p_values_dict[feature] = KS_p_value\n",
    "\n",
    "# Convert the dictionary to a DataFrame for better visualization\n",
    "ranking_df = pd.DataFrame(list(p_values_dict.items()), columns=['feature', 'KS p-value'])\n",
    "\n",
    "# Print the p-values DataFrame\n",
    "# print(\"\\nP-Values DataFrame:\\n\", ranking_df)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = KSTest_df.drop(target_column, axis=1).corr().abs()\n",
    "\n",
    "# Set threshold for high correlation\n",
    "corr_threshold_low = 0.5\n",
    "\n",
    "# Dictionary to store highly correlated features for each feature\n",
    "highly_correlated_features = {}\n",
    "\n",
    "# Loop through the features and find highly correlated features\n",
    "for feature in corr_matrix.columns:\n",
    "    highly_corr = corr_matrix[(corr_matrix[feature] > corr_threshold_low)][feature].index.tolist()\n",
    "    if highly_corr:\n",
    "        highly_correlated_features[feature] = highly_corr\n",
    "\n",
    "# Perform KS test for each group and keep the feature with the best p-value\n",
    "selected_features = set()\n",
    "ks_test_results = {}\n",
    "\n",
    "# DataFrame to store selected features and their p-values\n",
    "selected_features_df = pd.DataFrame(columns=['Group', 'Selected_Feature', 'p-value'])\n",
    "\n",
    "# Set to keep track of already selected features\n",
    "excluded_features = set()\n",
    "\n",
    "for feature, correlated in highly_correlated_features.items():\n",
    "    # Filter out already selected features\n",
    "    candidates = [col for col in correlated + [feature] if col not in excluded_features]\n",
    "    if not candidates:\n",
    "        continue\n",
    "    # Use precomputed p-values from the dictionary\n",
    "    p_values = {col: p_values_dict[col] for col in candidates}\n",
    "    ks_test_results[feature] = p_values\n",
    "    best_feature = min(p_values, key=p_values.get)\n",
    "    selected_features.add(best_feature)\n",
    "    excluded_features.update(candidates)\n",
    "    \n",
    "    # Add the selected feature and its p-value to the DataFrame\n",
    "    new_row = pd.DataFrame({'Group': [feature], 'Selected_Feature': [best_feature], 'p-value': [p_values[best_feature]]})\n",
    "    selected_features_df = pd.concat([selected_features_df, new_row], ignore_index=True)\n",
    "\n",
    "# Final set of features\n",
    "final_selected_features = list(selected_features)\n",
    "\n",
    "# Display the DataFrame of selected features and their p-values\n",
    "# print(\"\\nThis df has Selected Features and Their p-values:\\n\", selected_features_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(final_selected_features))\n",
    "check = set(final_selected_features)\n",
    "print(\"So unique would be\")\n",
    "print(len(check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming selected_features_df is your original DataFrame\n",
    "threshold = 0.05 / 3759\n",
    "\n",
    "# Initialize count and a list to store the rows that meet the criteria\n",
    "count = 0\n",
    "filtered_rows = []\n",
    "\n",
    "# Iterate over the rows in the DataFrame\n",
    "for index, row in selected_features_df.iterrows():\n",
    "    if row['p-value'] < threshold:\n",
    "        count += 1\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "# Create a new DataFrame from the filtered rows\n",
    "Pvalue_cutoff_df = pd.DataFrame(filtered_rows)\n",
    "\n",
    "print(\"number of features under  0.05 / 3759= \", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pvalue_cutoff_df.to_csv('C:/Users/shrra/Downloads/MASH_ML/Metab_corr_60features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is my first initial code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming KSTest_df is your DataFrame\n",
    "# # Calculate correlation matrix\n",
    "# corr_matrix = KSTest_df.drop('MASH', axis=1).corr().abs()\n",
    "\n",
    "# # Set threshold for high correlation\n",
    "# corr_threshold_low = 0.5\n",
    "# corr_threshold_high = 1.0\n",
    "\n",
    "# # Dictionary to store highly correlated features for each feature\n",
    "# highly_correlated_features = {}\n",
    "\n",
    "# # Loop through the features and find highly correlated features\n",
    "# for feature in corr_matrix.columns:\n",
    "#     highly_corr = corr_matrix[(corr_matrix[feature] > corr_threshold_low) & (corr_matrix[feature] < corr_threshold_high)][feature].index.tolist()\n",
    "#     if highly_corr:\n",
    "#         highly_correlated_features[feature] = highly_corr\n",
    "\n",
    "# # # Print the highly correlated features for each feature\n",
    "# # for feature, correlated in highly_correlated_features.items():\n",
    "# #     print(f\"Highly correlated features for {feature}: {correlated}\")\n",
    "\n",
    "# # Function to calculate p-value using KS test\n",
    "# def ks_test(feature, target):\n",
    "#     return ks_2samp(feature[target == 0], feature[target == 1]).pvalue\n",
    "\n",
    "# # Perform KS test for each group and keep the feature with the best p-value\n",
    "# selected_features = set()\n",
    "# ks_test_results = {}\n",
    "\n",
    "# # DataFrame to store selected features and their p-values\n",
    "# selected_features_df = pd.DataFrame(columns=['Group', 'Feature', 'p-value'])\n",
    "\n",
    "# # Set to keep track of already selected features\n",
    "# excluded_features = set()\n",
    "\n",
    "# for feature, correlated in highly_correlated_features.items():\n",
    "#     # Filter out already selected features\n",
    "#     candidates = [col for col in correlated + [feature] if col not in excluded_features]\n",
    "#     if not candidates:\n",
    "#         continue\n",
    "#     p_values = {col: ks_test(KSTest_df[col], KSTest_df['MASH']) for col in candidates}\n",
    "#     ks_test_results[feature] = p_values\n",
    "#     best_feature = min(p_values, key=p_values.get)\n",
    "#     selected_features.add(best_feature)\n",
    "#     excluded_features.add(best_feature)\n",
    "    \n",
    "#     # Add the selected feature and its p-value to the DataFrame\n",
    "#     new_row = pd.DataFrame({'Group': [feature], 'Selected_Feature': [best_feature], 'p-value': [p_values[best_feature]]})\n",
    "#     selected_features_df = pd.concat([selected_features_df, new_row], ignore_index=True)\n",
    "\n",
    "# # # Print KS test results and selected feature from each group\n",
    "# # print(\"\\nKS Test Results and Selected Features from Each Group:\\n\")\n",
    "# for feature, p_values in ks_test_results.items():\n",
    "#     best_feature = min(p_values, key=p_values.get)\n",
    "#     # print(f\"KS test p-values for group starting with {feature}: {p_values}, Best Feature: {best_feature}\")\n",
    "\n",
    "# # Final set of features\n",
    "# final_selected_features = list(selected_features)\n",
    "\n",
    "# # # Print the selected features\n",
    "# # print(\"\\nSelected Features:\\n\", final_selected_features)\n",
    "\n",
    "# # # Display the DataFrame of selected features and their p-values\n",
    "# # print(\"\\nThis df has Selected Features and Their p-values:\\n\", selected_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(final_selected_features))\n",
    "# check = set(final_selected_features)\n",
    "# print(\"So unique would be\")\n",
    "# print(len(check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count=0\n",
    "# for index, row in selected_features_df.iterrows():\n",
    "#     if row['p-value'] < (0.05/3759):\n",
    "#         count=count+1\n",
    "\n",
    "# print(\"number of features under 0.05= \",count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
