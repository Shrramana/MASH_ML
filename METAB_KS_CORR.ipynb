{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import kstest, mannwhitneyu\n",
    "from scipy.stats import ks_2samp\n",
    "import itertools\n",
    "# import shap\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pingouin as pg\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mz_time', 'C-1ZSH0', 'C-1ZUY0', 'C-1ZV09', 'C-1ZV17', 'C-1ZY97',\n",
      "       'C-1ZY89', 'C-1ZXQ5', 'C-1ZRJ6', 'C-1ZV25',\n",
      "       ...\n",
      "       '6204', '6888', '6957', '7010', '7021', '7106', '7519', '8938', '8950',\n",
      "       '9764'],\n",
      "      dtype='object', length=587)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "met_file_path = \"C:/Users/shrra/Downloads/merged_n586_Alasdair_May21_concatenated_renamed.csv\"\n",
    "met1_df = pd.read_csv(met_file_path)\n",
    "print(met1_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "met1_df_T  = met1_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', '85.9631_153.8', '86.0601_71.8', '86.0965_42.45', '86.9087_49.05',\n",
      "       '87.05525_82.6', '87.08045_28.6', '87.0935_42.95', '87.09985_44',\n",
      "       '88.0394_80',\n",
      "       ...\n",
      "       '1144.21635_54', '1145.28445_65.4', '1145.78475_65.45',\n",
      "       '1153.83065_66.15', '1168.74555_64.8', '1178.78305_64.8',\n",
      "       '1179.2791_65.5', '1179.77765_65.45', '1212.76635_65.5',\n",
      "       '1247.76475_65.65'],\n",
      "      dtype='object', name=0, length=3759)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "met1_df_T.reset_index(inplace=True)\n",
    "\n",
    "# Set the first row as the header\n",
    "met1_df_T.columns = met1_df_T.iloc[0]\n",
    "met1_df_T = met1_df_T[1:]\n",
    "\n",
    "# Reset the index again (if you want to have a clean numeric index)\n",
    "met1_df_T.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Rename the newly created index column (if needed)\n",
    "met1_df_T.rename(columns={met1_df_T.columns[0]: 'ID'}, inplace=True)\n",
    "\n",
    "# # Dictionary to map old column names to new column names\n",
    "# new_column_names = {\n",
    "#     'mz_time': 'ID'\n",
    "# }\n",
    "\n",
    "# # Renaming columns\n",
    "# met1_df_T = met1_df_T.rename(columns=new_column_names)\n",
    "print(met1_df_T.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586\n",
      "Index(['ID', '85.9631_153.8', '86.0601_71.8', '86.0965_42.45', '86.9087_49.05',\n",
      "       '87.05525_82.6', '87.08045_28.6', '87.0935_42.95', '87.09985_44',\n",
      "       '88.0394_80',\n",
      "       ...\n",
      "       '1144.21635_54', '1145.28445_65.4', '1145.78475_65.45',\n",
      "       '1153.83065_66.15', '1168.74555_64.8', '1178.78305_64.8',\n",
      "       '1179.2791_65.5', '1179.77765_65.45', '1212.76635_65.5',\n",
      "       '1247.76475_65.65'],\n",
      "      dtype='object', name=0, length=3759)\n"
     ]
    }
   ],
   "source": [
    "met1_df_T['ID'] = met1_df_T['ID'].str.replace('-S.*', '', regex=True)\n",
    "print(len(met1_df_T))\n",
    "print(met1_df_T.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'MASH', 'Age (yrs.)', 'Female n(%)', 'Hispanic race/ethnicity',\n",
      "       'BMI (kg/m2)', 'BMI z-score', 'WC (cm)', 'ALT (U/L)', 'AST (U/L)',\n",
      "       'GGT (U/L)', 'Glucose (mg/dL)', 'Insulin (uU/mL)', 'HOMA-IR',\n",
      "       'TG:HDL ratio', 'TG (mg/dL)', 'TC (mg/dL)', 'LDL-c (mg/dL)',\n",
      "       'HDL-c (mg/dL)', 'Bilirubin (mg/dL)', 'Creatinine (mg/dL)',\n",
      "       'Albumin (g/dL)', 'Alk phos (U/L)', 'Uric acid (mg/dL)',\n",
      "       'Platelet count', 'SBP', 'DBP'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "mas_file_path = \"C:/Users/shrra/Downloads/MASH_biomarkers_clinicaldata_notimputed_May30_HH.csv\"\n",
    "mash_df = pd.read_csv(mas_file_path)\n",
    "mash_df['MASH'] = mash_df['MASH'].map({'MASH': 1, 'non-MASH': 0})\n",
    "print(mash_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_df = mash_df[['ID', 'MASH']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrra\\AppData\\Local\\Temp\\ipykernel_25244\\3199667862.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  id_df['ID'] = id_df['ID'].str.replace('5-00', '')\n",
      "C:\\Users\\shrra\\AppData\\Local\\Temp\\ipykernel_25244\\3199667862.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  id_df['ID'] = id_df['ID'].str.replace('5-0', '')\n"
     ]
    }
   ],
   "source": [
    "id_df['ID'] = id_df['ID'].str.replace('5-00', '')\n",
    "id_df['ID'] = id_df['ID'].str.replace('5-0', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ID Values in mash file that are not in metab file\n",
      "set()\n",
      "0\n",
      "\n",
      "ID Values in metab file that are not in mash file\n",
      "set()\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df1 = id_df[['ID']]\n",
    "df2 = met1_df_T[['ID']]\n",
    "\n",
    "\n",
    "set1 = set(df1['ID'])\n",
    "set2 = set(df2['ID'])\n",
    "\n",
    "# Find values in df1['ID'] that are not in df2['ID']\n",
    "missing_in_df2 = set1 - set2\n",
    "\n",
    "# Find values in df2['ID'] that are not in df1['ID']\n",
    "missing_in_df1 = set2 - set1\n",
    "\n",
    "# Display the missing values\n",
    "print(\"\\nID Values in mash file that are not in metab file\")\n",
    "print(missing_in_df2)\n",
    "print(len(missing_in_df2))\n",
    "print(\"\\nID Values in metab file that are not in mash file\")\n",
    "print(missing_in_df1)\n",
    "print(len(missing_in_df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Updated_meta_df = pd.merge(id_df, met1_df_T, on=['ID'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "KSTest_df = Updated_meta_df\n",
    "\n",
    "\n",
    "excluded_cols = [\"ID\"]\n",
    "KSTest_df= KSTest_df.drop(columns=excluded_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrra\\AppData\\Local\\Temp\\ipykernel_25244\\216185983.py:49: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  selected_features_df = pd.concat([selected_features_df, new_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming KSTest_df is your DataFrame\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = KSTest_df.drop('MASH', axis=1).corr().abs()\n",
    "\n",
    "# Set threshold for high correlation\n",
    "corr_threshold_low = 0.8\n",
    "corr_threshold_high = 1.0\n",
    "\n",
    "# Dictionary to store highly correlated features for each feature\n",
    "highly_correlated_features = {}\n",
    "\n",
    "# Loop through the features and find highly correlated features\n",
    "for feature in corr_matrix.columns:\n",
    "    highly_corr = corr_matrix[(corr_matrix[feature] > corr_threshold_low) & (corr_matrix[feature] < corr_threshold_high)][feature].index.tolist()\n",
    "    if highly_corr:\n",
    "        highly_correlated_features[feature] = highly_corr\n",
    "\n",
    "# # Print the highly correlated features for each feature\n",
    "# for feature, correlated in highly_correlated_features.items():\n",
    "#     print(f\"Highly correlated features for {feature}: {correlated}\")\n",
    "\n",
    "# Function to calculate p-value using KS test\n",
    "def ks_test(feature, target):\n",
    "    return ks_2samp(feature[target == 0], feature[target == 1]).pvalue\n",
    "\n",
    "# Perform KS test for each group and keep the feature with the best p-value\n",
    "selected_features = set()\n",
    "ks_test_results = {}\n",
    "\n",
    "# DataFrame to store selected features and their p-values\n",
    "selected_features_df = pd.DataFrame(columns=['Group', 'Feature', 'p-value'])\n",
    "\n",
    "# Set to keep track of already selected features\n",
    "excluded_features = set()\n",
    "\n",
    "for feature, correlated in highly_correlated_features.items():\n",
    "    # Filter out already selected features\n",
    "    candidates = [col for col in correlated + [feature] if col not in excluded_features]\n",
    "    if not candidates:\n",
    "        continue\n",
    "    p_values = {col: ks_test(KSTest_df[col], KSTest_df['MASH']) for col in candidates}\n",
    "    ks_test_results[feature] = p_values\n",
    "    best_feature = min(p_values, key=p_values.get)\n",
    "    selected_features.add(best_feature)\n",
    "    excluded_features.add(best_feature)\n",
    "    \n",
    "    # Add the selected feature and its p-value to the DataFrame\n",
    "    new_row = pd.DataFrame({'Group': [feature], 'Selected_Feature': [best_feature], 'p-value': [p_values[best_feature]]})\n",
    "    selected_features_df = pd.concat([selected_features_df, new_row], ignore_index=True)\n",
    "\n",
    "# # Print KS test results and selected feature from each group\n",
    "# print(\"\\nKS Test Results and Selected Features from Each Group:\\n\")\n",
    "for feature, p_values in ks_test_results.items():\n",
    "    best_feature = min(p_values, key=p_values.get)\n",
    "    # print(f\"KS test p-values for group starting with {feature}: {p_values}, Best Feature: {best_feature}\")\n",
    "\n",
    "# Final set of features\n",
    "final_selected_features = list(selected_features)\n",
    "\n",
    "# # Print the selected features\n",
    "# print(\"\\nSelected Features:\\n\", final_selected_features)\n",
    "\n",
    "# # Display the DataFrame of selected features and their p-values\n",
    "# print(\"\\nThis df has Selected Features and Their p-values:\\n\", selected_features_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684\n",
      "684\n"
     ]
    }
   ],
   "source": [
    "print(len(final_selected_features))\n",
    "check = set(final_selected_features)\n",
    "\n",
    "print(len(check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for index, row in selected_features_df.iterrows():\n",
    "    if row['p-value'] < 0.05:\n",
    "        count=count+1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_features_df.rename(columns={'Feature': 'Selected_Feature'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_features_df.to_csv('C:/Users/shrra/Downloads/MASH_ML/Metab_group_corr.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
